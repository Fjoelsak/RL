{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Lecture: Implementation of Markov decision processes\n",
    "\n",
    "Suppose we have the markov decision process as depicted in the lecture slides."
   ],
   "id": "bb44e97e37a73a2c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "!git clone https://github.com/Fjoelsak/RL.git\n",
    "!cp RL/02_MDP/markov_decision_process.py ./"
   ],
   "id": "55bea5952467b60",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-03-17T14:44:29.251406Z",
     "start_time": "2025-03-17T14:44:29.078447Z"
    }
   },
   "source": [
    "import markov_decision_process as mdp\n",
    "\n",
    "# state space = [FB, C1, C2, C3, Sleep]\n",
    "states = list(range(5))\n",
    "\n",
    "# action space = [FB, Study, Quit, Sleep, Pub]\n",
    "actions = {0: [0, 2],\n",
    "           1: [0, 1],\n",
    "           2: [1, 3],\n",
    "           3: [1, 4],\n",
    "           4: []\n",
    "           }\n",
    "\n",
    "# rewards according to the process diagram from lecture slides\n",
    "rewards = {\n",
    "    (0,0) : -1,    (0,2) : 0,\n",
    "    (1,0) : -1,    (1,1) : -2,\n",
    "    (2,1) : -2,    (2,3) : 0,\n",
    "    (3,1) : 10,    (3,4) : 1\n",
    "}\n",
    "\n",
    "# transition probabilities according to the process diagram from lecture slides\n",
    "transProbs = {(0,0): {0: 1},\n",
    "        (0,2) : {1: 1},\n",
    "        (1,0) : {0: 1},\n",
    "        (1,1) : {2: 1},\n",
    "        (2,1) : {3: 1},\n",
    "        (2,3) : {4: 1},\n",
    "        (3,1) : {4: 1},\n",
    "        (3,4) : {1: 0.2, 2: 0.4, 3: 0.4}\n",
    "}\n",
    "\n",
    "Student_MDP = mdp.MarkovDecisionProcess(states, actions, rewards, transProbs, [4], 1)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: {0: 0.5, 2: 0.5}, 1: {0: 0.5, 1: 0.5}, 2: {1: 0.5, 3: 0.5}, 3: {1: 0.5, 4: 0.5}, 4: {}}\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Excercise: Analytical solution for an MDP for a given equally distributed policy",
   "id": "2042d8a092e9bcf1"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Task 1\n",
    "Implement the `sample()` method in the `MarkovDecisionProcess` class in `markov_decision_process.py` to sample trajectories from the MDP."
   ],
   "id": "3451c8357ee6c223"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-17T14:44:29.390370Z",
     "start_time": "2025-03-17T14:44:29.338778Z"
    }
   },
   "cell_type": "code",
   "source": "Student_MDP.sample(0)",
   "id": "57d6ffb34fd414bb",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 0, -1), (0, 0, -1), (0, 2, 0), (1, 1, -2), (2, 1, -2), (3, 1, 10)]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Task 2\n",
    "\n",
    "In the class `MarkovDecisionProcess`  in `markov_decision_process.py` a default policy is implemented as equally distributed policy. Implement the analytical solution introduced in the lecture slides by calculating $\\mathcal R^{\\pi}$ and $\\mathcal P^{\\pi}$ by averaging over the policy probabilities to the corresponding actions and apply the method already implemented for the markov reward process.\n"
   ],
   "id": "ac8784d5e54477db"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-17T14:22:03.962102Z",
     "start_time": "2025-03-17T14:22:03.945104Z"
    }
   },
   "cell_type": "code",
   "source": "Student_MDP.analytical_sol()    # result should be -2.3,-1.3, 2.7, 7.4, 0",
   "id": "fa3536efd0125b8a",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-2.30769231, -1.30769231,  2.69230769,  7.38461538,  0.        ])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
