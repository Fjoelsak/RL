{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Lecture: Implementation of Policy Iteration\n",
    "\n",
    "We want to implement policy iteration for the `frozen lake` environment provided by gymnasium. Gymnasium is a reinforcement learning (RL) environment library that provides a collection of pre-built environments for training and evaluating RL algorithms. It is a maintained fork of the original OpenAI Gym, which became unmaintained after OpenAI shifted focus.\n",
    "\n",
    "The Environments follow a universal API, making it easy to test different RL algorithms on various tasks.\n",
    "\n",
    "If you execute the code locally and have pygame installed as in the requirements.txt a window should pop up if you choose render_mode='human' showing the env and dynamics."
   ],
   "id": "e4c9fd936e65369a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "!git clone https://github.com/Fjoelsak/RL.git\n",
    "!cp RL/03_Dynamic_Programming/mdp_control.py ./"
   ],
   "id": "bf55810abd660a14",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "import gymnasium as gym\n",
    "\n",
    "env = gym.make('FrozenLake-v1',\n",
    "               desc = None,\n",
    "               map_name = \"4x4\",\n",
    "               is_slippery = False,\n",
    "               render_mode = 'human')\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "This is an exemplary use of the provided environment in which the agent takes a randomly sampled action in each state.",
   "id": "6aca89b3b387a1d2"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "obs,_ = env.reset()\n",
    "\n",
    "while True:\n",
    "    env.render()\n",
    "    action = env.action_space.sample()\n",
    "\n",
    "    obs, reward, terminated, truncated, _ = env.step(action)\n",
    "\n",
    "    if terminated or truncated:\n",
    "        break\n",
    "\n",
    "env.close()"
   ],
   "id": "6d8c6e30eaef0c99",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Excercise 1: Getting to know the environment\n",
    "\n",
    "Go to the farama [foundation docs of the environment](https://gymnasium.farama.org/environments/toy_text/frozen_lake/) and determine how the state and action spaces are defined, how the reward function is implemented and how the condition for a termination of the episode is implemented. In addition, check what the `is_slippery` boolean is doing."
   ],
   "id": "97b46a3cb4ec778f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "env.observation_space",
   "id": "4b02676c89f2c5d0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "env.action_space",
   "id": "ec248727778e4b51",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Excercise 2: Policy Iteration for the Frozen lake environment",
   "id": "bea9df9c60924490"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Check the class `mdpControl` in `mdp_control.py` and implement the functions `policy_evaluation()` and `policy_iteration()`.\n",
    "\n",
    "In order to get the transition probability matrix explicity you can use the unwrapped environment of the frozen lake env. With `env.unwrapped.P` you get for each state (0-15) for each action (0-3) the corresponding transition probability, next_state, reward and a done flag whether the episode is terminated."
   ],
   "id": "c33208a72fbfc1f6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "env.unwrapped.P",
   "id": "3e8aa4da87ba7755",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import mdp_control\n",
    "\n",
    "env = gym.make('FrozenLake-v1',\n",
    "               desc = None,\n",
    "               map_name = \"4x4\",\n",
    "               is_slippery = False,\n",
    "               render_mode = 'human')\n",
    "\n",
    "mdp = mdp_control.mdpControl(env)\n",
    "p, V = mdp.policy_iteration()\n",
    "\n",
    "# rendering of the agent acting in the env with your optimized policy\n",
    "mdp.render_single(p)\n",
    "env.close()"
   ],
   "id": "7864c350c102cb31",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Excercise 3: Value Iteration for the Frozen lake environment",
   "id": "3362d569064f006c"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Check the class `mdpControl` in `mdp_control.py` and implement the function `value_iteration()`.",
   "id": "293d07e26d74cc1b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import mdp_control\n",
    "\n",
    "env = gym.make('FrozenLake-v1',\n",
    "               desc = None,\n",
    "               map_name = \"4x4\",\n",
    "               is_slippery = False,\n",
    "               render_mode = 'human')\n",
    "\n",
    "\n",
    "mdp = mdp_control.mdpControl(env)\n",
    "p, V = mdp.value_iteration()\n",
    "\n",
    "# rendering of the agent acting in the env with your optimized policy\n",
    "mdp.render_single(p)\n",
    "env.close()"
   ],
   "id": "6aa3e3fb7335f472",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
