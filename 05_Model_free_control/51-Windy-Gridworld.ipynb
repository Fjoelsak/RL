{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# Windy Gridworld with Sarsa and extended action space"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the windy grid world problem, with the starting point **S** and the destination **G**. As shown in the diagram, there is a crosswind represented by the arrows, which moves the agent x fields up depending on the column.\n",
    "\n",
    "<img src=\"images/WindyGridworld.png\" alt=\"Drawing\" style=\"width: 600px;\"/>\n",
    "\n",
    "The respective strength of the wind is indicated below the columns.\tInitially, the actions are the so-called standard moves ``up, right, down, left``.\n",
    "For example, if the agent is one cell to the right of the target and moves to ``left``, it lands one cell above the target. Furthermore, we assume a non-discounted task that calculates a constant reward of $-1$ in each time step until the goal is reached."
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "The setup of the Excercise consists of this jupyter notebook as well as the two python modules ``windy.py`` and ``sarsa.py``. The former consists of the implementation of the environment whereas the latter all relevant methods for the agent are implemented. Be sure that all files are in the same directory for proper imports.\n",
    "The module ``sarsa.py`` consists of two methods ``run_episode()`` which applies the policy to the environment and visualizes the results and the method ``sarsa()`` which implements the SARSA algorithm from the lecture."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import gymnasium as gym\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# importieren der mitgelieferten Python Module, diese m√ºssen im gleichen Verzeichnis wie das Notebook liegen!\n",
    "import windy\n",
    "from sarsa import sarsa, run_episode"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Task 1\n",
    "Take a closer look at the **framework of the `sarsa` function** and implement the **SARSA algorithm** from the lecture using the given input parameters.\n",
    "The **output values** should include a table of $Q(s,a)$ values, a **stochastic policy**, and a `history` array containing the number of time steps per episode.\n",
    "The parameter $\\varepsilon$ should decay with the number of episodes $e$ according to\n",
    "$$\n",
    "\\varepsilon = \\frac{1}{e}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Initialisieren der Umgebung\n",
    "env = gym.make('WindyGridworld-v0', disable_env_checker=True)\n",
    "q, policy, history = sarsa(env, 500, eps0=0.5, alpha=0.5)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2\n",
    "\n",
    "Plot the episodes over the time steps. For correct display, the required time steps per episode must be stored in the `history` output array."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "plt.figure()\n",
    "plt.xlabel(\"Time steps\"); plt.xlim(0, 8_000)\n",
    "plt.ylabel(\"Episodes\"); plt.ylim(0, 170)\n",
    "timesteps = np.cumsum([0] + history)\n",
    "plt.plot(timesteps, np.arange(len(timesteps)), color='red')\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "Plot the value function and the policy indicated as arrows with the following ``plot_results()`` and ``run_episode()`` methods."
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import matplotlib\n",
    "from sarsa import plot_results\n",
    "\n",
    "matplotlib.rcParams['figure.figsize'] = [10, 10]\n",
    "\n",
    "plot_results(env, q, policy)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "rewards = run_episode(env, policy, render=True)\n",
    "print(f\"Episode length = {len(rewards)}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Task 3\n",
    "\n",
    "Now consider four additional possible actions using the so-called King's moves as shown in the illustration. These are diagonal movement options.\n",
    "Adapt the environment model in the file ``windy.py`` so that you define the additional actions and take these actions into account depending on the Boolean transfer parameter of the environment. What has changed?"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "env = gym.make('WindyGridworld-v0', king=True, disable_env_checker=True)\n",
    "q, policy, _ = sarsa(env, 500, eps0=0.5, alpha=0.5)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "plot_results(env, q, policy)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "rewards = run_episode(env, policy, render=True)\n",
    "print(f\"Episode length = {len(rewards)}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4\n",
    "\n",
    "Now consider an additional stop action. This allows for letting the wind blew the agent in the wind direction without additional moving.\n",
    "Adapt the environment model in the file ``windy.py`` so that you define the additional actions and take these actions into account depending on the Boolean transfer parameter of the environment. What has changed?"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "env = gym.make('WindyGridworld-v0', king=True, stop=True, disable_env_checker=True)\n",
    "q, policy, _ = sarsa(env, 500, eps0=0.5, alpha=0.5)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "plot_results(env, q, policy)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "rewards = run_episode(env, policy, render=True)\n",
    "print(f\"Episode length = {len(rewards)}\")"
   ],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
