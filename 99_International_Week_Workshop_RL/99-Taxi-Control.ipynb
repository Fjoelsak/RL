{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Workshop on Reinforcement Learning or How to drive a taxi in a data-driven way?\n",
    "\n",
    "Welcome to the workshop on Reinforcement Learning. We want to introduce the concept of Reinforcement Learning in a problem-based way with an interactive small example, the so called **Taxi environment**.\n",
    "\n",
    "There are four designated pick-up and drop-off locations (Red, Green, Yellow and Blue) in the 5x5 grid world. The taxi starts off at a random square and the passenger at one of the designated locations.\n",
    "\n",
    "The goal is move the taxi to the passenger’s location, pick up the passenger, move to the passenger’s desired destination, and drop off the passenger. Once the passenger is dropped off, the episode ends.\n",
    "\n",
    "The player receives positive rewards for successfully dropping-off the passenger at the correct location. Negative rewards for incorrect attempts to pick-up/drop-off passenger and for each step where another reward is not received.\n",
    "\n",
    "<img src=\"mat/taxi.gif\" alt=\"Taxi driver randomly driving around\" width=\"400\"/>\n",
    "\n",
    "More information can be found in the [official documentation](https://gymnasium.farama.org/environments/toy_text/taxi/)"
   ],
   "id": "1398e6433bbc037d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Excercise 1: Visualizing your agent in the environment",
   "id": "b1251e9146130cd7"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "For using the taxi environment you need the `gymnasium` package.\n",
    "\n",
    "If you use python locally, you can use the `pygame` package to visualize the game. If you use colab instead, you can create a video from your agent acting in the environment.\n",
    "At first, we want to try out the environment by instantiating it and setup the typical RL data stream we introduced in the slides:\n",
    "\n",
    "<img src=\"mat/01-RL-datastream.png\" alt=\"RL datastream\" width=\"400\"/>\n",
    "\n",
    "Therefore, we implement a `while` loop, sample an **action** from the possible actions in the action space and **do** one step with action in the environment. As an agent, we get the next state (called **observation**, short obs), a **reward** and some additional information whether the episode has ended."
   ],
   "id": "ad5656668a0e7803"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Note: Use the following code if you use python locally",
   "id": "bce1cca305adeaf5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import gymnasium as gym\n",
    "import pygame\n",
    "\n",
    "# instantiation of the environment\n",
    "env = gym.make('Taxi-v3', render_mode='human')\n",
    "# resetting the environment for first start\n",
    "obs, _ = env.reset()\n",
    "\n",
    "done = False\n",
    "while not done:\n",
    "    # sample an action\n",
    "    action = env.action_space.sample()\n",
    "    # do one step in the environment\n",
    "    obs, reward, terminated, truncated, _ = env.step(action)\n",
    "\n",
    "    # flag whether the episode is finished\n",
    "    done = terminated or truncated\n",
    "    # render the game\n",
    "    env.render()\n",
    "\n",
    "    # this is just event handling that you can end the visualization by clicking q button\n",
    "    for event in pygame.event.get():\n",
    "        if event.type == pygame.KEYDOWN:\n",
    "            if event.key == pygame.K_q:\n",
    "                pygame.quit()\n",
    "                done = True\n",
    "\n",
    "env.close()"
   ],
   "id": "d97ba13ff887398c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Note: Use the following code if you are using google colab",
   "id": "65137c7ddbe76f29"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import gymnasium as gym\n",
    "from IPython.display import HTML\n",
    "from base64 import b64encode\n",
    "\n",
    "import imageio\n",
    "\n",
    "# instantiation of the environment\n",
    "env = gym.make(\"Taxi-v3\", render_mode=\"rgb_array\")\n",
    "\n",
    "# resetting the environment for first start\n",
    "obs, _ = env.reset()\n",
    "\n",
    "# initialize a list of frames for video creation\n",
    "frames = []\n",
    "\n",
    "done = False\n",
    "while not done:\n",
    "    # capture the frame and append it to frames list\n",
    "    frame = env.render()\n",
    "    frames.append(frame)\n",
    "\n",
    "    # sample an action\n",
    "    action = env.action_space.sample()\n",
    "    # do one step in the environment\n",
    "    obs, reward, terminated, truncated, info = env.step(action)\n",
    "\n",
    "    # flag whether the episode is finished\n",
    "    done = terminated or truncated\n",
    "\n",
    "    # final rendering for last image of episode\n",
    "    if done:\n",
    "      frame = env.render()\n",
    "      frames.append(frame)\n",
    "\n",
    "env.close()\n",
    "\n",
    "# save video as\n",
    "video_path = \"./taxi_vid.mp4\"\n",
    "imageio.mimsave(video_path, frames, fps=5)"
   ],
   "id": "55a102b46d7f139d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# this is for displaying the video after saving\n",
    "mp4 = open(video_path, 'rb').read()\n",
    "data_url = \"data:video/mp4;base64,\" + b64encode(mp4).decode()\n",
    "\n",
    "HTML(f\"\"\"\n",
    "<video width=400 controls>\n",
    "    <source src=\"{data_url}\" type=\"video/mp4\">\n",
    "</video>\n",
    "\"\"\")"
   ],
   "id": "61887b6d1f53483",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Excercise 2\n",
    "\n",
    "Find out the dimensions of state and action space and check it with the ideas we introduced theortically before."
   ],
   "id": "422ca5d9fc23243e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "print(\"Dimension observation space: \", env.observation_space.n)",
   "id": "e755f084530da8b7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "print(\"Dimension action space: \", env.action_space.n)",
   "id": "d744f5a551d2f8ce",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Excercise 3\n",
    "\n",
    "How would you build up and implement a strategy for the taxi driver to properly solve the taxi problem? Try out some thoughts and hardcode the optimal policy for a given problem instance. Look at the following situation which is defined as state 328:\n",
    "\n",
    "<img src=\"mat/taxi-seed328.png\" alt=\"Taxi problem state 328\" width=\"400\"/>\n",
    "\n",
    "- think about the exact order of actions you have to do\n",
    "- hardcode them in a list and try it out!\n",
    "\n",
    "Remark: The actions are encoded in the following way according to the documentation:\n",
    "\n",
    "- 0: Move south (down)\n",
    "- 1: Move north (up)\n",
    "- 2: Move east (right)\n",
    "- 3: Move west (left)\n",
    "- 4: Pickup passenger\n",
    "-5: Drop off passenger\n",
    "\n",
    "**Note**: from here on I will always provide the two options for visualizing either in local python setup or in colab"
   ],
   "id": "9c25897808f4b2e2"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Note: Use the following code if you use python locally",
   "id": "56de745b632dc95d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import gymnasium as gym\n",
    "import pygame\n",
    "\n",
    "# instantiation of the environment\n",
    "env = gym.make('Taxi-v3', render_mode='human')\n",
    "# reseting the environment for first start\n",
    "obs, _ = env.reset()\n",
    "\n",
    "# consider a specific problem instance\n",
    "env.unwrapped.s = 328\n",
    "\n",
    "done = False\n",
    "while not done:\n",
    "    # sample an action\n",
    "    action = env.action_space.sample()\n",
    "    # do one step in the environment\n",
    "    obs, reward, terminated, truncated, _ = env.step(action)\n",
    "\n",
    "    # flag whether the episode is finished\n",
    "    done = terminated or truncated\n",
    "    # render the game\n",
    "    env.render()\n",
    "\n",
    "    # this is just event handling that you can end the visualization by clicking q button\n",
    "    for event in pygame.event.get():\n",
    "        if event.type == pygame.KEYDOWN:\n",
    "            if event.key == pygame.K_q:\n",
    "                pygame.quit()\n",
    "                done = True\n",
    "\n",
    "env.close()"
   ],
   "id": "5de293bd2cad68ee",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Note: Use the following code if you use google colab",
   "id": "253186a989875d60"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import gymnasium as gym\n",
    "from IPython.display import HTML\n",
    "from base64 import b64encode\n",
    "\n",
    "import imageio\n",
    "\n",
    "# instantiation of the environment\n",
    "env = gym.make(\"Taxi-v3\", render_mode=\"rgb_array\")\n",
    "\n",
    "# resetting the environment for first start\n",
    "obs, _ = env.reset()\n",
    "\n",
    "# consider a specific problem instance\n",
    "env.unwrapped.s = 328\n",
    "\n",
    "# initialize a list of frames for video creation\n",
    "frames = []\n",
    "\n",
    "done = False\n",
    "while not done:\n",
    "    # capture the frame and append it to frames list\n",
    "    frame = env.render()\n",
    "    frames.append(frame)\n",
    "\n",
    "    # sample an action\n",
    "    action = env.action_space.sample()\n",
    "    # do one step in the environment\n",
    "    obs, reward, terminated, truncated, info = env.step(action)\n",
    "\n",
    "    # flag whether the episode is finished\n",
    "    done = terminated or truncated\n",
    "\n",
    "    # final rendering for last image of episode\n",
    "    if done:\n",
    "      frame = env.render()\n",
    "      frames.append(frame)\n",
    "\n",
    "env.close()\n",
    "\n",
    "# save video as\n",
    "video_path = \"./taxi_vid_own_policy.mp4\"\n",
    "imageio.mimsave(video_path, frames, fps=5)"
   ],
   "id": "70d9a3d904d323ab",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# this is for displaying the video after saving\n",
    "mp4 = open(video_path, 'rb').read()\n",
    "data_url = \"data:video/mp4;base64,\" + b64encode(mp4).decode()\n",
    "\n",
    "HTML(f\"\"\"\n",
    "<video width=400 controls>\n",
    "    <source src=\"{data_url}\" type=\"video/mp4\">\n",
    "</video>\n",
    "\"\"\")"
   ],
   "id": "8b1f5f918cd325d2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Excercise 4\n",
    "\n",
    "Let's start learning! Recall from the slides that there is an approach called Q-learning based von a Q-value function for each state-action pair. Doing updates wrt\n",
    "$$ Q(s,a) \\leftarrow Q(s,a) + \\alpha( r_{t+1} + \\gamma \\cdot \\max_{a} Q(s',a) - Q(s,a)) $$\n",
    "provides the optimal Q-function. Starting with a lot of exploration and estimating $Q(s,a)$ in each time step for the states and action we have experienced leads to the optimal function. Finally we can get the optimal policy by using the $\\text{arg} \\max_a Q(s,a)$ in each state.\n"
   ],
   "id": "79bc9df0564da5bd"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import gymnasium as gym\n",
    "import numpy as np\n",
    "\n",
    "# instantiation of the environment\n",
    "env = gym.make('Taxi-v3')\n",
    "# reseting the environment for first start\n",
    "\n",
    "def Qlearn(env, alpha, gamma, max_eps):\n",
    "    Q = np.zeros([env.observation_space.n], [env.action_space.n])\n",
    "\n",
    "    for eps in range(max_eps):\n",
    "        obs, _ = env.reset()\n",
    "        done = False\n",
    "        while not done:\n",
    "            # sample an action\n",
    "            action = env.action_space.sample()\n",
    "            # do one step in the environment\n",
    "            next_obs, reward, terminated, truncated, _ = env.step(action)\n",
    "\n",
    "            # update step\n",
    "            Q[obs, action] = Q[obs, action] + alpha*(reward + gamma*np.max(Q[next_obs, :]) - Q[obs, action])\n",
    "            obs = next_obs\n",
    "\n",
    "\n",
    "\n",
    "    env.close()"
   ],
   "id": "8f16fbe3baddd0f9",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
